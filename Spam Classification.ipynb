{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html\n",
    "input_data = pandas.read_table(r'Inputs/SMSSpamCollection.txt',\n",
    "                                  header=None,\n",
    "                                  names=['Class','Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a27c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d354cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['labels'] = input_data.apply(lambda r:0 if r['Class']=='ham' else 1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a038488",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['lower'] = input_data['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} Records\".format(len(input_data))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b44903",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(input_data['lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data_tokens = tokenizer.texts_to_sequences(input_data['lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data_tokens = tf.keras.preprocessing.sequence.pad_sequences(class_data_tokens, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb97c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['preprocessed'] = list(class_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b983c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(input_data, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = numpy.array(train_df['labels'].values)\n",
    "val_labels = numpy.array(val_df['labels'].values)\n",
    "test_labels = numpy.array(test_df['labels'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3744049",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dacf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = numpy.array([a for a in train_df['preprocessed'].values])\n",
    "val_features = numpy.array([a for a in val_df['preprocessed'].values])\n",
    "test_features = numpy.array([a for a in test_df['preprocessed'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://nlp.stanford.edu/projects/glove/\n",
    "#https://github.com/stanfordnlp/GloVe\n",
    "#In use is the embedding from wikipedia\n",
    "#Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 300d vectors, 822 MB download): glove.6B.zip\n",
    "GLOVE_EMBEDDING = \"Inputs/glove.6B.50d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    " \n",
    "with open(GLOVE_EMBEDDING, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        embed = numpy.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embed\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec27d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    " \n",
    "num_words = min(max_words, len(word_index) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eacea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50\n",
    "embedding_matrix = numpy.zeros((num_words, embed_size), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3788e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    " \n",
    "    if i >= max_words:\n",
    "        continue\n",
    " \n",
    "    embedding_vector = embeddings_index.get(word)\n",
    " \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef841079",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(max_words,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fe2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Embedding(max_words, embed_size, weights=[embedding_matrix], trainable=False)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f140320",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, dropout=0.1,\n",
    "                                                      recurrent_dropout=0.1))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f810f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv1D(64, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "max_pool = tf.keras.layers.GlobalMaxPooling1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de80ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.concatenate([avg_pool, max_pool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2fcec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    " \n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75550abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594d1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "    cp_callback\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91142d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_labels, batch_size=batch_size,\n",
    "          epochs=20, validation_data=(val_features, val_labels), callbacks=callbacks,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, history_dict['loss'], 'bo', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, history_dict['accuracy'], 'bo', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b978c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, history_dict['precision'], 'bo', label='Training prec')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, history_dict['recall'], 'bo', label='Training reca')\n",
    "#plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0737eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    " \n",
    "model.load_weights(latest)\n",
    "\n",
    "val_results = model.evaluate(test_features,test_labels, batch_size=batch_size)\n",
    "print(\"Loss: {:0.4f}\".format(val_results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc14804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
